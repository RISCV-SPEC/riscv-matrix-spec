== Standard Matrix Extensions

=== Zmv: Matrix for Vector operations

The Zmv extension is defined to provide matrix support with the RISC-V Vector "V" extension.

The Zmv extension allows to load matrix tile slices into vector registers, and move data between slices of a matrix register and vector registers.
// Element-wise multiply between a matrix register and a vector register(broadcast to a matrix) is also supported.

The data layout examples of registers and memory in Zmv are shown below.

image::memory-registers.svg[Data layout examples of registers and memory]

==== Load Instructions

```
# vd destination, rs1 base address, rs2 row byte stride
# lmul / (eew/sew) rows or columns

# for left matrix, a
mlae8.v    vd, (rs1), rs2 #  8-bit tile slices load to vregs
mlae16.v   vd, (rs1), rs2 # 16-bit tile slices load to vregs
mlae32.v   vd, (rs1), rs2 # 32-bit tile slices load to vregs
mlae64.v   vd, (rs1), rs2 # 64-bit tile slices load to vregs

# for right matrix, b
mlbe8.v    vd, (rs1), rs2 #  8-bit tile slices load to vregs
mlbe16.v   vd, (rs1), rs2 # 16-bit tile slices load to vregs
mlbe32.v   vd, (rs1), rs2 # 32-bit tile slices load to vregs
mlbe64.v   vd, (rs1), rs2 # 64-bit tile slices load to vregs

# for output matrix, c
mlce8.v    vd, (rs1), rs2 #  8-bit tile slices load to vregs
mlce16.v   vd, (rs1), rs2 # 16-bit tile slices load to vregs
mlce32.v   vd, (rs1), rs2 # 32-bit tile slices load to vregs
mlce64.v   vd, (rs1), rs2 # 64-bit tile slices load to vregs
```

==== Store Instructions

```
# vs3 store data, rs1 base address, rs2 row byte stride
# lmul / (eew/sew) rows or columns

# for left matrix, a
msae8.v    vs3, (rs1), rs2 #  8-bit tile slices store from vregs
msae16.v   vs3, (rs1), rs2 # 16-bit tile slices store from vregs
msae32.v   vs3, (rs1), rs2 # 32-bit tile slices store from vregs
msae64.v   vs3, (rs1), rs2 # 64-bit tile slices store from vregs

# for right matrix, b
msbe8.v    vs3, (rs1), rs2 #  8-bit tile slices store from vregs
msbe16.v   vs3, (rs1), rs2 # 16-bit tile slices store from vregs
msbe32.v   vs3, (rs1), rs2 # 32-bit tile slices store from vregs
msbe64.v   vs3, (rs1), rs2 # 64-bit tile slices store from vregs

# for output matrix, c
msce8.v    vs3, (rs1), rs2 #  8-bit tile slices store from vregs
msce16.v   vs3, (rs1), rs2 # 16-bit tile slices store from vregs
msce32.v   vs3, (rs1), rs2 # 32-bit tile slices store from vregs
msce64.v   vs3, (rs1), rs2 # 64-bit tile slices store from vregs
```


==== Data Move Instructions

Normal data move, rows or columns = lmul, eew = sew.

```
# Data move between matrix register rows and vector registers.

# vd[(i - rs2) * tile_n + j] = td[i, j], i = rs2 .. rs2 + lmul - 1
mmvar.v.m  vd, ts1, rs2
mmvbr.v.m  vd, ts1, rs2
mmvcr.v.m  vd, ts1, rs2

# td[i, j] = vd[(i - rs2) * tile_n + j], i = rs2 .. rs2 + lmul - 1
mmvar.m.v  td, vs1, rs2
mmvbr.m.v  td, vs1, rs2
mmvcr.m.v  td, vs1, rs2

# Data move between matrix register columns and vector registers.

# vd[(j - rs2) * tile_m + i] = td[i, j], j = rs2 .. rs2 + lmul - 1
mmvac.v.m  vd, ts1, rs2
mmvbc.v.m  vd, ts1, rs2
mmvcc.v.m  vd, ts1, rs2

# td[i, j] = vd[(j - rs2) * tile_m + i], j = rs2 .. rs2 + lmul - 1
mmvac.m.v  td, vs1, rs2
mmvbc.m.v  td, vs1, rs2
mmvcc.m.v  td, vs1, rs2
```

// Double widen data move, rows or columns = lmul / 2, eew = sew * 2.

// Only support accumulator registers as source and destination registers.

// ```
// # Data move between matrix register rows and vector registers.

// # vd[(i - rs2) * tile_n + j] = td[i, j], i = rs2 .. rs2 + lmul/2 - 1
// mwmvcr.v.m  vd, ts1, rs2

// # td[i, j] = vd[(i - rs2) * tile_n + j], i = rs2 .. rs2 + lmul/2 - 1
// mwmvcr.m.v  td, vs1, rs2


// # Data move between matrix register columns and vector registers.

// # vd[(j - rs2) * tile_m + i] = td[i, j], j = rs2 .. rs2 + lmul/2 - 1
// mwmvcc.v.m  vd, ts1, rs2

// # td[i, j] = vd[(j - rs2) * tile_m + i], j = rs2 .. rs2 + lmul/2 - 1
// mwmvcc.m.v  td, vs1, rs2
// ```


// quadruple widen data move, rows or columns = lmul / 4, eew = sew * 4.

// Only support accumulator registers as source and destination registers.

// ```
// # Data move between matrix register rows and vector registers.

// # vd[(i - rs2) * tile_n + j] = td[i, j], i = rs2 .. rs2 + lmul/4 - 1
// mqmvcr.v.m  vd, ts1, rs2  # vl = lmul * tile_n

// # td[i, j] = vd[(i - rs2) * tile_n + j], i = rs2 .. rs2 + lmul/4 - 1
// mqmvcr.m.v  td, vs1, rs2  # vl = lmul * tile_n


// # Data move between matrix register columns and vector registers.

// # vd[(j - rs2) * tile_m + i] = td[i, j], j = rs2 .. rs2 + lmul/4 - 1
// mqmvcc.v.m  vd, ts1, rs2  # vl = lmul * tile_m

// # td[i, j] = vd[(j - rs2) * tile_m + i], j = rs2 .. rs2 + lmul/4 - 1
// mqmvcc.m.v  td, vs1, rs2  # vl = lmul * tile_m
// ```

// ==== Matrix element-wise multiply

// Matrix element-wise multiply instructions, the vector operand will broadcast to a matrix.

// For m*emulcr.mv instructions, the vector operand will broadcast from a row to a c matrix.

// ```
// # int matrix element-wise multiply with a row of vector int
// # td[i,j] = ts1[i,j] * vs2[j]
// memulcr.mv td, ts1, vs2
// mwemulcr.mv td, ts1, vs2  # output double widen
// mqemulcr.mv td, ts1, vs2  # output quadruple widen

// # float matrix element-wise multiply with a row of vector float
// # td[i,j] = ts1[i,j] * vs2[j]
// mfemulcr.mv td, ts1, vs2
// mfwemulcr.mv td, ts1, vs2  # output double widen
// ```

// For m*emulcc.mv instructions, the vector operand will broadcast from a column to a c matrix.

// ```
// # int matrix element-wise multiply with a column of vector int,
// # td[i,j] = ts1[i,j] * vs2[i]
// memulcc.mv td, ts1, vs2
// mwemulcc.mv td, ts1, vs2  # output double widen
// mqemulcc.mv td, ts1, vs2  # output quadruple widen

// # float matrix element-wise multiply with a column of vector float,
// # td[i,j] = ts1[i,j] * vs2[i]
// mfemulcc.mv td, ts1, vs2
// mfwemulcc.mv td, ts1, vs2  # output double widen
// ```

// ==== Matrix element-wise add

// Matrix element-wise add instructions, the vector operand will broadcast to a matrix.

// For m*addcr.mv instructions, the vector operand will broadcast from a row to a c matrix.

// ```
// # int matrix element-wise add with a row of vector int
// # td[i,j] = ts1[i,j] + vs2[j]
// maddcr.mv td, ts1, vs2
// mwaddcr.mv td, ts1, vs2  # output double widen
// mqaddcr.mv td, ts1, vs2  # output quadruple widen

// # float matrix element-wise add with a row of vector float
// # td[i,j] = ts1[i,j] + vs2[j]
// mfaddcr.mv td, ts1, vs2
// mfwaddcr.mv td, ts1, vs2  # output double widen
// ```

// For m*addcc.mv instructions, the vector operand will broadcast from a column to a c matrix.

// ```
// # int matrix element-wise add with a column of vector int,
// # td[i,j] = ts1[i,j] + vs2[i]
// maddcc.mv td, ts1, vs2
// mwaddcc.mv td, ts1, vs2  # output double widen
// mqaddcc.mv td, ts1, vs2  # output quadruple widen

// # float matrix element-wise add with a column of vector float,
// # td[i,j] = ts1[i,j] + vs2[i]
// mfaddcc.mv td, ts1, vs2
// mfwaddcc.mv td, ts1, vs2  # output double widen
// ```

// ==== Matrix element-wise fused multiply-accumulate

// Matrix element-wise fused multiply-add instructions, the vector operand will broadcast to a matrix.

// For m*macccr.mv instructions, the vector operand will broadcast from a row to a c matrix.

// ```
// # int matrix element-wise multiply-accumulate with a row of vector int
// # td[i,j] = vs1[j] * td[i,j] + vs2[j]
// mmacccr.mv td, vs1, vs2
// mwmacccr.mv td, vs1, vs2  # output double widen
// mqmacccr.mv td, vs1, vs2  # output quadruple widen

// # float matrix element-wise multiply-accumulate with a row of vector float
// # td[i,j] = vs1[j] * td[i,j] + vs2[j]
// mfmacccr.mv td, vs1, vs2
// mfwmacccr.mv td, vs1, vs2  # output double widen
// ```

// For m*macccc.mv instructions, the vector operand will broadcast from a column to a c matrix.

// ```
// # int matrix element-wise multiply-accumulate with a column of vector int,
// # td[i,j] = vs1[i] * td[i,j] + vs2[i]
// mmacccc.mv td, vs1, vs2
// mwmacccc.mv td, vs1, vs2  # output double widen
// mqmacccc.mv td, vs1, vs2  # output quadruple widen

// # float matrix element-wise add with a column of vector float,
// # td[i,j] = vs1[i] * td[i,j] + vs2[i]
// mfmacccc.mv td, vs1, vs2
// mfwmacccc.mv td, vs1, vs2  # output double widen
// ```

==== Instruction Listing

[cols="^2,5,^3,^2,^2,^2,^2,^2,^3"]
|===
| No.  |          | **31  26** | 25   | 24 20 | 19 15 | 14  12 | 11 7 | 6    0

2+|**Load**            ^| funct6 | ls   | rs2   | rs1   | eew    | vd   | opcode
| 1    | mlae8.v        | 100001 | 0    | rs2   | rs1   | 000    | vd   | 1110111
| 2    | mlae16.v       | 100001 | 0    | rs2   | rs1   | 001    | vd   | 1110111
| 3    | mlae32.v       | 100001 | 0    | rs2   | rs1   | 010    | vd   | 1110111
| 4    | mlae64.v       | 100001 | 0    | rs2   | rs1   | 011    | vd   | 1110111
| 5    | mlbe8.v        | 100010 | 0    | rs2   | rs1   | 000    | vd   | 1110111
| 6    | mlbe16.v       | 100010 | 0    | rs2   | rs1   | 001    | vd   | 1110111
| 7    | mlbe32.v       | 100010 | 0    | rs2   | rs1   | 010    | vd   | 1110111
| 8    | mlbe64.v       | 100010 | 0    | rs2   | rs1   | 011    | vd   | 1110111
| 9    | mlce8.v        | 100000 | 0    | rs2   | rs1   | 000    | vd   | 1110111
| 10   | mlce16.v       | 100000 | 0    | rs2   | rs1   | 001    | vd   | 1110111
| 11   | mlce32.v       | 100000 | 0    | rs2   | rs1   | 010    | vd   | 1110111
| 12   | mlce64.v       | 100000 | 0    | rs2   | rs1   | 011    | vd   | 1110111

2+|**Store**           ^| funct6 | ls   | rs2   | rs1   | eew    | vs3  | opcode
| 13   | msae8.v        | 100001 | 1    | rs2   | rs1   | 000    | vs3  | 1110111
| 14   | msae16.v       | 100001 | 1    | rs2   | rs1   | 001    | vs3  | 1110111
| 15   | msae32.v       | 100001 | 1    | rs2   | rs1   | 010    | vs3  | 1110111
| 16   | msae64.v       | 100001 | 1    | rs2   | rs1   | 011    | vs3  | 1110111
| 17   | msbe8.v        | 100010 | 1    | rs2   | rs1   | 000    | vs3  | 1110111
| 18   | msbe16.v       | 100010 | 1    | rs2   | rs1   | 001    | vs3  | 1110111
| 19   | msbe32.v       | 100010 | 1    | rs2   | rs1   | 010    | vs3  | 1110111
| 20   | msbe64.v       | 100010 | 1    | rs2   | rs1   | 011    | vs3  | 1110111
| 21   | msce8.v        | 100000 | 1    | rs2   | rs1   | 000    | vs3  | 1110111
| 22   | msce16.v       | 100000 | 1    | rs2   | rs1   | 001    | vs3  | 1110111
| 23   | msce32.v       | 100000 | 1    | rs2   | rs1   | 010    | vs3  | 1110111
| 24   | msce64.v       | 100000 | 1    | rs2   | rs1   | 011    | vs3  | 1110111


2+|**Data Move**       ^| funct6 | v2m  | rs2   | *s1   | funct3 | *d   | opcode
| 25   | mmvar.v.m      | 000101 | 0    | rs2   | ts1   | 101    | vd   | 1110111
| 26   | mmvar.m.v      | 000101 | 1    | rs2   | vs1   | 101    | td   | 1110111
| 27   | mmvbr.v.m      | 000110 | 0    | rs2   | ts1   | 101    | vd   | 1110111
| 28   | mmvbr.m.v      | 000110 | 1    | rs2   | vs1   | 101    | td   | 1110111
| 29   | mmvcr.v.m      | 000100 | 0    | rs2   | ts1   | 101    | vd   | 1110111
| 30   | mmvcr.m.v      | 000100 | 1    | rs2   | vs1   | 101    | td   | 1110111

| 31   | mmvac.v.m      | 001001 | 0    | rs2   | ts1   | 101    | vd   | 1110111
| 32   | mmvac.m.v      | 001001 | 1    | rs2   | vs1   | 101    | td   | 1110111
| 33   | mmvbc.v.m      | 001010 | 0    | rs2   | ts1   | 101    | vd   | 1110111
| 34   | mmvbc.m.v      | 001010 | 1    | rs2   | vs1   | 101    | td   | 1110111
| 35   | mmvcc.v.m      | 001000 | 0    | rs2   | ts1   | 101    | vd   | 1110111
| 36   | mmvcc.m.v      | 001000 | 1    | rs2   | vs1   | 101    | td   | 1110111

// | 37   | mwmvcr.v.m     | 010000 | 0    | rs2   | ts1   | 101    | vd   | 1110111
// | 38   | mwmvcr.m.v     | 010000 | 1    | rs2   | vs1   | 101    | td   | 1110111

// | 39   | mwmvcc.v.m     | 010100 | 0    | rs2   | ts1   | 101    | vd   | 1110111
// | 40   | mwmvcc.m.v     | 010100 | 1    | rs2   | vs1   | 101    | td   | 1110111

// | 41   | mqmvcr.v.m     | 100000 | 0    | rs2   | ts1   | 101    | vd   | 1110111
// | 42   | mqmvcr.m.v     | 100000 | 1    | rs2   | vs1   | 101    | td   | 1110111

// | 43   | mqmvcc.v.m     | 100100 | 0    | rs2   | ts1   | 101    | vd   | 1110111
// | 44   | mqmvcc.m.v     | 100100 | 1    | rs2   | vs1   | 101    | td   | 1110111

// 2+|**Arithmetic**      ^| funct6 | fp   | vs2   | ts1   | funct3 | td   | opcode
// | 45   | memulcr.mv     | 100001 | 0    | vs2   | ts1   | 110    | td   | 1110111
// | 46   | mfemulcr.mv    | 100001 | 1    | vs2   | ts1   | 110    | td   | 1110111
// | 47   | mwemulcr.mv    | 100010 | 0    | vs2   | ts1   | 110    | td   | 1110111
// | 48   | mfwemulcr.mv   | 100010 | 1    | vs2   | ts1   | 110    | td   | 1110111
// | 49   | mqemulcr.mv    | 100011 | 0    | vs2   | ts1   | 110    | td   | 1110111
// | 50   | memulcc.mv     | 100100 | 0    | vs2   | ts1   | 110    | td   | 1110111
// | 51   | mfemulcc.mv    | 100100 | 1    | vs2   | ts1   | 110    | td   | 1110111
// | 52   | mwemulcc.mv    | 100101 | 0    | vs2   | ts1   | 110    | td   | 1110111
// | 53   | mfwemulcc.mv   | 100101 | 1    | vs2   | ts1   | 110    | td   | 1110111
// | 54   | mqemulcc.mv    | 100110 | 0    | vs2   | ts1   | 110    | td   | 1110111

// | 55   | maddcr.mv      | 100111 | 0    | vs2   | ts1   | 110    | td   | 1110111
// | 56   | mfaddcr.mv     | 100111 | 1    | vs2   | ts1   | 110    | td   | 1110111
// | 57   | mwaddcr.mv     | 101000 | 0    | vs2   | ts1   | 110    | td   | 1110111
// | 58   | mfwaddcr.mv    | 101000 | 1    | vs2   | ts1   | 110    | td   | 1110111
// | 59   | mqaddcr.mv     | 101001 | 0    | vs2   | ts1   | 110    | td   | 1110111
// | 60   | maddcc.mv      | 101010 | 0    | vs2   | ts1   | 110    | td   | 1110111
// | 61   | mfaddcc.mv     | 101010 | 1    | vs2   | ts1   | 110    | td   | 1110111
// | 62   | mwaddcc.mv     | 101011 | 0    | vs2   | ts1   | 110    | td   | 1110111
// | 63   | mfwaddcc.mv    | 101011 | 1    | vs2   | ts1   | 110    | td   | 1110111
// | 64   | mqaddcc.mv     | 101100 | 0    | vs2   | ts1   | 110    | td   | 1110111

// | 55   | mmacccr.mv     | 101101 | 0    | vs2   | vs1   | 110    | td   | 1110111
// | 56   | mfmacccr.mv    | 101101 | 1    | vs2   | vs1   | 110    | td   | 1110111
// | 57   | mwmacccr.mv    | 101110 | 0    | vs2   | vs1   | 110    | td   | 1110111
// | 58   | mfwmacccr.mv   | 101110 | 1    | vs2   | vs1   | 110    | td   | 1110111
// | 59   | mqmacccr.mv    | 101111 | 0    | vs2   | vs1   | 110    | td   | 1110111
// | 60   | mmacccc.mv     | 110000 | 0    | vs2   | vs1   | 110    | td   | 1110111
// | 61   | mfmacccc.mv    | 110000 | 1    | vs2   | vs1   | 110    | td   | 1110111
// | 62   | mwmacccc.mv    | 110001 | 0    | vs2   | vs1   | 110    | td   | 1110111
// | 63   | mfwmacccc.mv   | 110001 | 1    | vs2   | vs1   | 110    | td   | 1110111
// | 64   | mqmacccc.mv    | 110010 | 0    | vs2   | vs1   | 110    | td   | 1110111

|===


====  Intrinsic Examples: Matrix multiplication fused with element-wise vector operation

```
void fused_matmul_relu_float16(c, a, b, m, k, n) {
    msettype(e16, m1);                          // use 16bit input matrix element
    for (i = 0; i < m; i += tile_m) {           // loop at dim m with tiling
        tile_m = msettile_m(m-i);
        for (j = 0; j < n; j += tile_n) {       // loop at dim n with tiling
            tile_n = msettile_n(n-j);

            out = mfemul_mf(out, 0.f, m2)       // clear acc reg
            for (s = 0; s < k; s += tile_k) {   // loop at dim k with tiling
                tile_k = msettile_k(k-s);

                tr1 = mlae16_m(&a[i][s]);       // load left matrix a
                tr2 = mlbe16_m(&b[s][j]);       // load right matrix b
                out = mfwma_mm(tr1, tr2);       // tiled matrix multiply,
                                                // double widen output
            }

            out = mfncvt_f_fw_m(out, m2);       // convert widen result to single


            for (s = 0; s < tile_m; s += rows) {
                rows = min(tile_m - s, 8*vlenb/rlenb); // max rows could move into 8 vregs
                vsetvl(tile_n*rows, e16, m8);

                v1 = mmvcr_v_m(out, s);         // move out rows to vreg
                v1 = vfmax_vf(0.f, v1);         // vfmax.vf for relu

                msce16_v(v1, &c[i+s][j], n);    // store output tile slices
            }
        }
    }
}

```

=== Zmbf16: Matrix Bfloat16(BF16) Extension

The Zmbf16 extension allows to use BF16 format as the data type of input matrix elements.

The Zmbf16 extension adds a bit `mtype[7]` in `mtype` register.

.`mtype` register layout
[cols="^2,^2,8"]
|===
|     Bits | Name       | Description

|   XLEN-1 | mill       | Illegal value if set.
| XLEN-2:8 | 0          | Reserved if non-zero.
|        7 | **mbf16**  | Support BFloat16 format.
|        6 | mfp64      | Support 64-bit float point.
|        5 | mba        | Matrix out of bound agnostic.
|      4:2 | msew[2:0]  | Selected element width (SEW) setting.
|      1:0 | mlmul[1:0] | Register group multiplier (LMUL) setting.
|===


The new `mtype` value is encoded in the immediate fields of msettypei, and in the rs1 register for msettype.

```
Suggested bf16 assembler name used for msettypei mtypei immediate

    bf16  # Use BF16 format

Examples:

    msettypei t0, e16, bf16         # SEW = 16, use BF16 as input matrix element

```

For implemention not support Bfloat16 format, `mtype.mill` will be set.

`bf16` should be always used with `e16`(SEW=16), otherwise `mtype.mill` will be set.


=== Zmtf32: Matrix TensorFloat-32(TF32) Extension

The Zmtf32 extension allows to use TF32 FMA for matrix multiplication.

TF32 implementions are designed to achieve better performance on matrix multiplications and convolutions
by rounding input Float32 data to have 10 bits of mantissa, and accumulating results with FP32 precision,
maintaining FP32 dynamic range.

So when Zmtf32 is used, Float32 is still used as the input and output data type for matrix multiplication.

The Zmtf32 extension adds a bit `mtype[8]` in `mtype` register.

.`mtype` register layout
[cols="^2,^2,8"]
|===
|     Bits | Name       | Description

|   XLEN-1 | mill       | Illegal value if set.
| XLEN-2:9 | 0          | Reserved if non-zero.
|        8 | **mtf32**  | Support TensorFloat32 format.
|        7 | mbf16      | Support BFloat16 format.
|        6 | mfp64      | Support 64-bit float point.
|        5 | mba        | Matrix out of bound agnostic.
|      4:2 | msew[2:0]  | Selected element width (SEW) setting.
|      1:0 | mlmul[1:0] | Register group multiplier (LMUL) setting.
|===

The new `mtype` value is encoded in the immediate fields of msettypei, and in the rs1 register for msettype.

```
Suggested tf32 assembler name used for msettypei mtypei immediate

    tf32  # enable TF32 FMA

Examples:

    msettypei t0, e32, tf32         # SEW = 32, enable TF32 FMA

```

For implemention not support TF32 format, `mtype.mill` will be set.

`tf32` should be always used with `e32`(SEW=32), otherwise `mtype.mill` will be set.


=== Zmfp8: Matrix 8-bit Float Point Extension

The Zmfp8 extension allows to use 8-bit float point format as the data type of input matrix elements.

The Zmfp8 extension adds a bit `mtype[9]` in `mtype` register.

.`mtype` register layout
[cols="^2,^2,8"]
|===
|     Bits  | Name       | Description

|   XLEN-1  | mill       | Illegal value if set.
| XLEN-2:10 | 0          | Reserved if non-zero.
|        9  | **mfp8**   | Support 8-bit float point format.
|        8  | mtf32      | Support TensorFloat32 format.
|        7  | mbf16      | Support BFloat16 format.
|        6  | mfp64      | Support 64-bit float point.
|        5  | mba        | Matrix out of bound agnostic.
|      4:2  | msew[2:0]  | Selected element width (SEW) setting.
|      1:0  | mlmul[1:0] | Register group multiplier (LMUL) setting.
|===

The Zmfp8 extension adds another unprivileged CSR (mfcsr) to the base scalar RISC-V ISA.

.New matrix CSR
[cols="^2,^2,^2,10",options="header"]
|===
| Address | Privilege   | Name   | Description

| 0xXXX | URW | mfcsr   | Matrix float point control and status.
|===

.`mfcsr` register layout
[cols="^2,^2,8"]
|===
|     Bits  | Name        | Description

| XLEN-1:4  | 0           | Reserved if non-zero.
|      3:1  | mftype[2:0] | The types of ts1, ts2 and td.
|        0  | mfsat       | If to saturate the FP8 result.
|===

The CSR `mfcsr` is valid when `mtype.mfp8=1`.

The bits mftype[0], mftype[1] and mftype[2] specify the type of ts1, ts2 and td, respectively.

.`mftype` bit
[cols="^2,8"]
|===
| Value | Type

| 0     | E4M3, with 4-bit exponent and 3-bit mantissa.
| 1     | E5M2, with 5-bit exponent and 2-bit mantissa.
|===

If `mfsat=1`, the result of an FP8 operation will be saturated to the maximum value of the corresponding type. Otherwise, the result will be set to NaN and Infinity for E4M3 and E5M2, respectively.

The new `mtype` value is encoded in the immediate fields of msettypei, and in the rs1 register for msettype.

```
Suggested fp8 assembler name used for msettypei mtypei immediate

    fp8   # Use FP8 format

Examples:

    msettypei t0, e8, fp8           # SEW = 8, use FP8 as input matrix element

```

For implemention not support FP8 format, `mtype.mill` will be set.

`fp8` should be always used with `e8`(SEW=8), otherwise `mtype.mill` will be set.

The float-point matrix multiplication and add instructions, `mfma.mm` and `mfwma.mm`, are reused for FP8 format. A quad-widen instruction is added for quad-widening matrix multiplication and add for FP8 format.

```
# Float matrix multiplication and add, td = td + ts1 * ts2
mfma.mm   td, ts1, ts2
mfwma.mm  td, ts1, ts2  # output double widen
mfqma.mm  td, ts1, ts2  # output quadruple widen
```

The element-wise instructions are not available under FP8 format.

==== Instruction Listing

[cols="^3,7,^5,^2,^3,^2,^2,^3,^3,^3,^3,^5"]
|===
| No.  |           | **31  26** | 25 | 24 20 | 19 | 18 | 17 15 | 14  12 | 11 10 | 9 7 | 6    0
2+|**Arithmetic**     ^| funct6 | fp | *s2   | sn | sa | ts1   | funct3 | lmul  | td  | opcode
| 1    | mfqma.mm      | 000010 | 1  | ts2   | 0  | 0  | ts1   | 110    | 00    | td  | 1110111
|===


=== Zmi4: Matrix 4-bit Integer (INT4) Extension

The Zmi4 extension allows to use 4-bit integer as the data type of input matrix elements.

The Zmi4 extension adds a bit `mtype[10]` in `mtype` register.

.`mtype` register layout
[cols="^2,^2,8"]
|===
|     Bits  | Name       | Description

|    XLEN-1 | mill       | Illegal value if set.
| XLEN-2:11 | 0          | Reserved if non-zero.
|        10 | **mint4**  | Support 4-bit integer.
|         9 | mfp8       | Support 8-bit float point format.
|         8 | mtf32      | Support TensorFloat32 format.
|         7 | mbf16      | Support BFloat16 format.
|         6 | mfp64      | Support 64-bit float point.
|         5 | mba        | Matrix out of bound agnostic.
|       4:2 | msew[2:0]  | Selected element width (SEW) setting.
|       1:0 | mlmul[1:0] | Register group multiplier (LMUL) setting.
|===

The new `mtype` value is encoded in the immediate fields of msettypei, and in the rs1 register for msettype.

```
Suggested int4 assembler name used for msettypei mtypei immediate

    int4   # Use INT4 format

Examples:

    msettypei t0, e8, int4           # SEW = 8, use INT4 as input matrix element

```

For implemention not support INT4 format, `mtype.mill` will be set.

`int4` should be always used with `e8`(SEW=8), otherwise `mtype.mill` will be set. Two 4-bit values are combined to a 8-bit element in tile register. So the size of a row must be even.

The integer matrix multiplication and add instructions, both unsigned one and signed one, are reused for INT4 format.

The element-wise instructions are not available under INT4 format.

The Zmbf16, Zmtf32, Zmfp8, Zmi4 extensions can be implemented with any combination.


=== Zmic: Im2col Matrix Multiplication Extension

Im2col stands for Image to Column, and is an implementation technique of computing Convolution operation
(in Machine Learning) using GEMM operations.

The Zmic extension allows to perform the im2col operation on-the-fly, by the new load instructions.

The **Load Unfold** instructions allows to load and extract sliding local blocks from memory into the matrix tile registers.
And also, **Store Fold** instructions allows to store and combine an array of sliding local blocks from the matrix tile regstiers into memory.
Similar to PyTorch, for the case of two output spatial dimensions this operation is sometimes called `col2im`.

==== CSRs

The matrix extension adds 7 unprivileged CSRs (moutsh, minsh, mpad, mstdi, minsk, moutsk, mpadval) to the base scalar RISC-V ISA.

.New matrix CSRs
[cols="^2,^2,^2,10",options="header"]
|===
| Address | Privilege   | Name   | Description

| 0xXXX | URO | moutsh  | Fold/unfold output shape.
| 0xXXX | URO | minsh   | Fold/unfold input shape.
| 0xXXX | URO | mpad    | Fold/unfold padding parameters.
| 0xXXX | URO | mstdi   | Fold/unfold sliding strides and dilations.
| 0xXXX | URO | minsk   | Fold/unfold sliding kernel position of input.
| 0xXXX | URO | moutsk  | Fold/unfold sliding kernel position of output.
| 0xXXX | URO | mpadval | Fold/unfold padding value, default to zero.
|===


.`minsh` `moutsh` register layout
[cols="^2,^2,8"]
|===
|     Bits | Name       | Description

|  XLEN:32 | 0          | Reserved
|    31:16 | shape[1]   | shape of dim 1, height
|     15:0 | shape[0]   | shape of dim 0, width
|===

.`mpad` register layout
[cols="^2,^2,8"]
|===
|     Bits | Name        | Description

|  XLEN:32 | 0           | Reserved
|    31:24 | mpad_top    | Padding added to up side of input
|    23:16 | mpad_bottom | Padding added to bottom side of input
|     15:8 | mpad_left   | Padding added to left side of input
|      7:0 | mpad_right  | Padding added to left side of input
|===

.`mstdi` register layout
[cols="^2,^2,8"]
|===
|     Bits | Name        | Description

|  XLEN:32 | 0           | Reserved
|    31:24 | tdil_h      | Height spacing of the kernel elements
|    23:16 | tdil_w      | Weight spacing of the kernel elements
|     15:8 | mstr_h      | Height stride of the convolution
|      7:0 | mstr_w      | Weight stride of the convolution
|===

.`minsk` `moutsk` register layout
[cols="^2,^2,8"]
|===
|     Bits | Name        | Description

|  XLEN:32 | 0           | Reserved
|    31:16 | msk[1]      | Sliding kernel position of dim 1, height
|     15:0 | msk[0]      | Sliding kernel position of dim 0, width
|===

==== Configuration Instructions

```
msetoutsh  rd, rs1, rs2 # set output shape(rs1), strides and dilations(rs2)
msetinsh   rd, rs1, rs2 # set input shape(rs1) and padding(rs2)
msetsk     rd, rs1, rs2 # set fold/unfold sliding positions, insk(rs1), outsk(rs2)
msetpadval rd, rs1      # set fold/unfold padding value
```


==== Load Unfold Instructions

The **Load Unfold** instructions allows to load and extract sliding local blocks from memory into the matrix tile registers.
Similar to PyTorch, for the case of two input spatial dimensions this operation is sometimes called `im2col`.

Unfolded load and folded store only support LMUL=1. Other LMUL settings will be ignored.

```
# td destination, rs1 base address, rs2 row byte stride

# for left matrix, a
mlufae8.m    td, (rs1), rs2
mlufae16.m   td, (rs1), rs2
mlufae32.m   td, (rs1), rs2
mlufae64.m   td, (rs1), rs2

# for left matrix, b
mlufbe8.m    td, (rs1), rs2
mlufbe16.m   td, (rs1), rs2
mlufbe32.m   td, (rs1), rs2
mlufbe64.m   td, (rs1), rs2

# for left matrix, c
mlufce8.m    td, (rs1), rs2
mlufce16.m   td, (rs1), rs2
mlufce32.m   td, (rs1), rs2
mlufce64.m   td, (rs1), rs2
```

==== Store Fold Instructions

The **Store Fold** instructions allows to store and combine an array of sliding local blocks from the matrix tile regstiers into memory.
Similar to PyTorch, for the case of two output spatial dimensions this operation is sometimes called `col2im`.

```
# ts3 destination, rs1 base address, rs2 row byte stride

# for left matrix, a
msfdae8.m    ts3, (rs1), rs2
msfdae16.m   ts3, (rs1), rs2
msfdae32.m   ts3, (rs1), rs2
msfdae64.m   ts3, (rs1), rs2

# for left matrix, b
msfdbe8.m    ts3, (rs1), rs2
msfdbe16.m   ts3, (rs1), rs2
msfdbe32.m   ts3, (rs1), rs2
msfdbe64.m   ts3, (rs1), rs2

# for left matrix, c
msfdce8.m    ts3, (rs1), rs2
msfdce16.m   ts3, (rs1), rs2
msfdce32.m   ts3, (rs1), rs2
msfdce64.m   ts3, (rs1), rs2
```

==== Instruction Listing

[cols="^2,5,^3,^2,^2,^2,^2,^2,^3"]
|===
| No.  |             | **31  28** | 27 25 | 24 20 | 19 15 | 14  12 | 11 7 | 6    0
2+|**Configuration**   ^|funct4   | 000   | rs2   | rs1   | funct3 | rd   | opcode
| 1    | msetoutsh      | 1000    | 000   | rs2   | rs1   | 111    | rd   | 1110111
| 2    | msetinsh       | 1001    | 000   | rs2   | rs1   | 111    | rd   | 1110111
| 3    | msetsk         | 1010    | 000   | rs2   | rs1   | 111    | rd   | 1110111
| 4    | msetpadval     | 1011  2+| 00000000      | rs1   | 111    | rd   | 1110111



| No.  |            | **31  26** | 25   | 24 20 | 19 15 | 14  12 | 11 7 | 6    0
2+|**Load**            ^| funct6 | ls   | rs2   | rs1   | eew    | td   | opcode
| 1    | mlufae8.m      | 110001 | 0    | rs2   | rs1   | 000    | td   | 1110111
| 2    | mlufae16.m     | 110001 | 0    | rs2   | rs1   | 001    | td   | 1110111
| 3    | mlufae32.m     | 110001 | 0    | rs2   | rs1   | 010    | td   | 1110111
| 4    | mlufae64.m     | 110001 | 0    | rs2   | rs1   | 011    | td   | 1110111
| 5    | mlufbe8.m      | 110010 | 0    | rs2   | rs1   | 000    | td   | 1110111
| 6    | mlufbe16.m     | 110010 | 0    | rs2   | rs1   | 001    | td   | 1110111
| 7    | mlufbe32.m     | 110010 | 0    | rs2   | rs1   | 010    | td   | 1110111
| 8    | mlufbe64.m     | 110010 | 0    | rs2   | rs1   | 011    | td   | 1110111
| 9    | mlufce8.m      | 110000 | 0    | rs2   | rs1   | 000    | td   | 1110111
| 10   | mlufce16.m     | 110000 | 0    | rs2   | rs1   | 001    | td   | 1110111
| 11   | mlufce32.m     | 110000 | 0    | rs2   | rs1   | 010    | td   | 1110111
| 12   | mlufce64.m     | 110000 | 0    | rs2   | rs1   | 011    | td   | 1110111

2+|**Store**           ^| funct6 | ls   | rs2   | rs1   | eew    | ts3  | opcode
| 13   | msfdae8.m      | 110001 | 1    | rs2   | rs1   | 000    | ts3  | 1110111
| 14   | msfdae16.m     | 110001 | 1    | rs2   | rs1   | 001    | ts3  | 1110111
| 15   | msfdae32.m     | 110001 | 1    | rs2   | rs1   | 010    | ts3  | 1110111
| 16   | msfdae64.m     | 110001 | 1    | rs2   | rs1   | 011    | ts3  | 1110111
| 17   | msfdbe8.m      | 110010 | 1    | rs2   | rs1   | 000    | ts3  | 1110111
| 18   | msfdbe16.m     | 110010 | 1    | rs2   | rs1   | 001    | ts3  | 1110111
| 19   | msfdbe32.m     | 110010 | 1    | rs2   | rs1   | 010    | ts3  | 1110111
| 20   | msfdbe64.m     | 110010 | 1    | rs2   | rs1   | 011    | ts3  | 1110111
| 21   | msfdce8.m      | 110000 | 1    | rs2   | rs1   | 000    | ts3  | 1110111
| 22   | msfdce16.m     | 110000 | 1    | rs2   | rs1   | 001    | ts3  | 1110111
| 23   | msfdce32.m     | 110000 | 1    | rs2   | rs1   | 010    | ts3  | 1110111
| 24   | msfdce64.m     | 110000 | 1    | rs2   | rs1   | 011    | ts3  | 1110111
|===


====  Intrinsic Examples: Conv2D

```
void conv2d_float16(c, a, b, outh, outw, outc, inh, inw, inc,
        kh, kw, pt, pb, pl, pr, sw, dh, dw) {
    m = outh * outw;
    k = kh * kw * inc;
    n = outc;

    msettype(e16, m1);      // use 16bit input matrix element

    // set in/out shape, sliding strides and dilations, and padding
    msetoutsh(outh << 16 | outw, dh << 24 | dw << 16 | sh << 8 | sw);
    msetinsh(inh << 16 | inw, pt << 24 | pb << 16 | pl << 8 | pr);

    for (i = 0; i < m; i += tile_m) {               // loop at dim m with tiling
        tile_m = msettile_m(m-i);

        outh_pos = i / outw;
        outw_pos = i - outh_pos * outw;

        for (j = 0; j < n; j += tile_n) {           // loop at dim n with tiling
            tile_n = msettile_n(n-j);

            out = mwsub_mm(out, out, m1)            // clear output reg
            for (skh = 0; skh < kh; skh++) {        // loop for kernel height
                inh_pos = outh_pos * sh - pt + skh * dh;
                for (skw = 0; skw < kw; skw++) {    // loop for kernel width
                    inw_pos = outw_pos * sw - pl + skw * dw;

                    // set sliding position
                    msetsk(inh_pos << 16 | inw_pos, skw * dw << 16 | outw_pos)
                                                    
                    // loop for kernel channels
                    for (skc = 0; skc < inc; skc += tile_k) { 
                        tile_k = msettile_k(inc-skc);

                        tr1 = mlufae16_m(&a[inh_pos][inw_pos][skc]);
                                                    // load and unfold input blocks
                        tr2 = mlbe16_m(&b[s][j]);   // load right matrix b
                        out = mfwma_mm(tr1, tr2);   // tiled matrix multiply,
                                                    // double widen output
                    }
                }
            }

            out = mfncvt_f_fw_m(out, m2);           // convert widen result
            msce16_m(out, &c[i][j], n*2);           // store to matrix c
        }
    }
}

```

====  Intrinsic Examples: Conv3D

```
void conv3d_float16(c, a, b, outh, outw, outc, ind, inh, inw, inc,
        kd, kh, kw, pt, pb, pl, pr, sw, dh, dw) {
    m = outh * outw;
    k = kd * kh * kw * inc;
    n = outc;

    msettype(e16, m1);      // use 16bit input matrix element

    // set in/out shape, sliding strides and dilations, and padding
    msetoutsh(outh << 16 | outw, dh << 24 | dw << 16 | sh << 8 | sw);
    msetinsh(inh << 16 | inw, pt << 24 | pb << 16 | pl << 8 | pr);

    for (i = 0; i < m; i += tile_m) {               // loop at dim m with tiling
        tile_m = msettile_m(m-i);

        outh_pos = i / outw;
        outw_pos = i - outh_pos * outw;

        for (j = 0; j < n; j += tile_n) {           // loop at dim n with tiling
            tile_n = msettile_n(n-j);

            out = mwsub_mm(out, out, m1)            // clear output reg
            for (skd = 0; skd < kd; skd++) {        // loop for kernel *depth*
                for (skh = 0; skh < kh; skh++) {    // loop for kernel height
                    inh_pos = outh_pos * sh - pt + skh * dh;
                    for (skw = 0; skw < kw; skw++) {    // loop for kernel width
                        inw_pos = outw_pos * sw - pl + skw * dw;

                        msetsk(inh_pos << 16 | inw_pos, skw * dw << 16 | outw_pos)
                                                        // set sliding position

                        for (skc = 0; skc < inc; skc += tile_k) {
                            tile_k = msettile_k(inc-skc);

                            tr1 = mlufae16_m(&a[skd][inh_pos][inw_pos][skc]);
                                                        // load and unfold blocks
                            tr2 = mlbe16_m(&b[s][j]);   // load right matrix b
                            out = mfwma_mm(tr1, tr2);   // tiled matrix multiply,
                                                        // double widen output
                        }
                    }
                }
            }

            out = mfncvt_f_fw_m(out, m2);   // convert widen result
            msce16_m(out, &c[i][j], n*2);   // store to matrix c
        }
    }
}

```

====  Intrinsic Examples: MaxPool2D

```
void maxpool2d_float16(out, in, outh, outw, outc, inh, inw, inc,
        kh, kw, pt, pb, pl, pr, sw, dh, dw) {
    m = outh * outw;
    n = outc;

    msettype(e16, m1);      // use 16bit input matrix element

    // set in/out shape, sliding strides and dilations, and padding
    msetoutsh(outh << 16 | outw, dh << 24 | dw << 16 | sh << 8 | sw);
    msetinsh(inh << 16 | inw, pt << 24 | pb << 16 | pl << 8 | pr);

    for (i = 0; i < m; i += tile_m) {           // loop at dim m with tiling
        tile_m = msettile_m(m-i);

        outh_pos = i / outw;
        outw_pos = i - outh_pos * outw;

        for (j = 0; j < n; j += tile_n) {       // loop at dim n with tiling
            tile_n = msettile_n(n-j);

            tr_out = mfmv_s_f(tr_out, -inf)     // move -inf to output reg
            tr_out = mbcce_m (tr_out)           // fill -inf to output reg
            for (skh = 0; skh < kh; skh++) {    // loop for kernel height
                inh_pos = outh_pos * sh - pt + skh * dh;
                for (skw = 0; skw < kw; skw++) {        // loop for kernel width
                    inw_pos = outw_pos * sw - pl + skw * dw;

                    msetsk(inh_pos << 16 | inw_pos, skw * dw << 16 | outw_pos)
                                                        // set sliding position

                    // load and unfold matrix blocks
                    tr_in = mlufce16_m(&in[inh_pos][inw_pos][j]);
                    tr_out = mfmax_mm(tr_out, tr_in);
                }
            }

            msce16_m(tr_out, &out[i][j], n*2);  // store to matrix c
        }
    }
}

```

====  Intrinsic Examples: AvgPool2D

```
void avgpool2d_float16(out, in, outh, outw, outc, inh, inw, inc,
        kh, kw, pt, pb, pl, pr, sw, dh, dw) {
    m = outh * outw;
    n = outc;

    msettype(e16, m1);      // use 16bit input matrix element

    // set in/out shape, sliding strides and dilations, and padding
    msetoutsh(outh << 16 | outw, dh << 24 | dw << 16 | sh << 8 | sw);
    msetinsh(inh << 16 | inw, pt << 24 | pb << 16 | pl << 8 | pr);

    // set divider
    tr_div = mfmv_s_f(tr_div, kh*kw)
    tr_div = mbcce_m (tr_div)

    for (i = 0; i < m; i += tile_m) {   // loop at dim m with tiling
        tile_m = msettile_m(m-i);

        outh_pos = i / outw;
        outw_pos = i - outh_pos * outw;

        for (j = 0; j < n; j += tile_n) {   // loop at dim n with tiling
            tile_n = msettile_n(n-j);

            tr_out = mwsub_mm(tr_out, tr_out, m1)   // clear output reg
            for (skh = 0; skh < kh; skh++) {        // loop for kernel height
                inh_pos = outh_pos * sh - pt + skh * dh;
                for (skw = 0; skw < kw; skw++) {    // loop for kernel width
                    inw_pos = outw_pos * sw - pl + skw * dw;

                    msetsk(inh_pos << 16 | inw_pos, skw * dw << 16 | outw_pos)
                                                    // set sliding position

                    // load and unfold matrix blocks
                    tr_in = mlufce16_m(&in[inh_pos][inw_pos][j]);
                    tr_out = mfadd_mm(tr_out, tr_in);
                }
            }

            tr_out = mfdiv_mm(tr_out, tr_div);
            msce16_m(tr_out, &out[i][j], n*2);      // store to matrix c
        }
    }
}

```

=== Zmsp: Matrix Sparsity Extension

Work in progress.
