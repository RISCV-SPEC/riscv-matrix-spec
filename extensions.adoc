== Standard Matrix Extensions

=== Zmv: Matrix for Vector operations

The Zmv extension is defined to provide matrix support with the RISC-V Vector
"V" extension.

The Zmv extension allows to load matrix tile slices into vector registers, and
move data between slices of a matrix register and vector registers.
Element-wise multiply between a matrix register and a vector register(broadcast
to a matrix) is also supported.

The data layout examples of registers and memory in Zmv are shown below.

image::memory-registers.svg[Data layout examples of registers and memory]

==== Load Instructions

```
# vd destination, rs1 base address, rs2 row byte stride
# lmul / (eew/sew) rows or columns

# for left matrix, a
mlae8.v    vd, (rs1), rs2 #  8-bit tile/acc slices load to vregs
mlae16.v   vd, (rs1), rs2 # 16-bit tile/acc slices load to vregs
mlae32.v   vd, (rs1), rs2 # 32-bit tile/acc slices load to vregs
mlae64.v   vd, (rs1), rs2 # 64-bit tile/acc slices load to vregs

# for right matrix, b
mlbe8.v    vd, (rs1), rs2 #  8-bit tile/acc slices load to vregs
mlbe16.v   vd, (rs1), rs2 # 16-bit tile/acc slices load to vregs
mlbe32.v   vd, (rs1), rs2 # 32-bit tile/acc slices load to vregs
mlbe64.v   vd, (rs1), rs2 # 64-bit tile/acc slices load to vregs

# for output matrix, c
mlce8.v    vd, (rs1), rs2 #  8-bit tile/acc slices load to vregs
mlce16.v   vd, (rs1), rs2 # 16-bit tile/acc slices load to vregs
mlce32.v   vd, (rs1), rs2 # 32-bit tile/acc slices load to vregs
mlce64.v   vd, (rs1), rs2 # 64-bit tile/acc slices load to vregs
```

==== Store Instructions

```
# vs3 store data, rs1 base address, rs2 row byte stride
# lmul / (eew/sew) rows or columns

# for left matrix, a
msae8.v    vs3, (rs1), rs2 #  8-bit tile/acc slices store from vregs
msae16.v   vs3, (rs1), rs2 # 16-bit tile/acc slices store from vregs
msae32.v   vs3, (rs1), rs2 # 32-bit tile/acc slices store from vregs
msae64.v   vs3, (rs1), rs2 # 64-bit tile/acc slices store from vregs

# for right matrix, b
msbe8.v    vs3, (rs1), rs2 #  8-bit tile/acc slices store from vregs
msbe16.v   vs3, (rs1), rs2 # 16-bit tile/acc slices store from vregs
msbe32.v   vs3, (rs1), rs2 # 32-bit tile/acc slices store from vregs
msbe64.v   vs3, (rs1), rs2 # 64-bit tile/acc slices store from vregs

# for output matrix, c
msce8.v    vs3, (rs1), rs2 #  8-bit tile/acc slices store from vregs
msce16.v   vs3, (rs1), rs2 # 16-bit tile/acc slices store from vregs
msce32.v   vs3, (rs1), rs2 # 32-bit tile/acc slices store from vregs
msce64.v   vs3, (rs1), rs2 # 64-bit tile/acc slices store from vregs
```


==== Data Move Instructions

Normal data move, rows or columns = lmul, eew = sew.

```
# Data move between matrix register rows and vector registers.

# vd[(i - rs2) * tile_n + j] = md[i, j], i = rs2 .. rs2 + lmul - 1
mmvar.v.m  vd, ms1, rs2
mmvbr.v.m  vd, ms1, rs2
mmvcr.v.m  vd, ms1, rs2

# md[i, j] = vd[(i - rs2) * tile_n + j], i = rs2 .. rs2 + lmul - 1
mmvar.m.v  md, vs1, rs2
mmvbr.m.v  md, vs1, rs2
mmvcr.m.v  md, vs1, rs2

# Data move between matrix register columns and vector registers.

# vd[(j - rs2) * tile_m + i] = md[i, j], j = rs2 .. rs2 + lmul - 1
mmvac.v.m  vd, ms1, rs2
mmvbc.v.m  vd, ms1, rs2
mmvcc.v.m  vd, ms1, rs2

# md[i, j] = vd[(j - rs2) * tile_m + i], j = rs2 .. rs2 + lmul - 1
mmvac.m.v  md, vs1, rs2
mmvbc.m.v  md, vs1, rs2
mmvcc.m.v  md, vs1, rs2
```

Double widen data move, rows or columns = lmul / 2, eew = sew * 2.

Only support accumulator registers as source and destination registers.

```
# Data move between matrix register rows and vector registers.

# vd[(i - rs2) * tile_n + j] = md[i, j], i = rs2 .. rs2 + lmul/2 - 1
mwmvcr.v.m  vd, ms1, rs2

# md[i, j] = vd[(i - rs2) * tile_n + j], i = rs2 .. rs2 + lmul/2 - 1
mwmvcr.m.v  md, vs1, rs2


# Data move between matrix register columns and vector registers.

# vd[(j - rs2) * tile_m + i] = md[i, j], j = rs2 .. rs2 + lmul/2 - 1
mwmvcc.v.m  vd, ms1, rs2

# md[i, j] = vd[(j - rs2) * tile_m + i], j = rs2 .. rs2 + lmul/2 - 1
mwmvcc.m.v  md, vs1, rs2
```


quadruple widen data move, rows or columns = lmul / 4, eew = sew * 4.

Only support accumulator registers as source and destination registers.

```
# Data move between matrix register rows and vector registers.

# vd[(i - rs2) * tile_n + j] = md[i, j], i = rs2 .. rs2 + lmul/4 - 1
mqmvcr.v.m  vd, ms1, rs2  # vl = lmul * tile_n

# md[i, j] = vd[(i - rs2) * tile_n + j], i = rs2 .. rs2 + lmul/4 - 1
mqmvcr.m.v  md, vs1, rs2  # vl = lmul * tile_n


# Data move between matrix register columns and vector registers.

# vd[(j - rs2) * tile_m + i] = md[i, j], j = rs2 .. rs2 + lmul/4 - 1
mqmvcc.v.m  vd, ms1, rs2  # vl = lmul * tile_m

# md[i, j] = vd[(j - rs2) * tile_m + i], j = rs2 .. rs2 + lmul/4 - 1
mqmvcc.m.v  md, vs1, rs2  # vl = lmul * tile_m
```

==== Matrix element-wise multiply

Matrix element-wise multiply instructions, the vector operand will broadcast to a matrix.

For m*emulcr.mv instructions, the vector operand will broadcast from a row to a c matrix.

```
# int matrix element-wise multiply with a row of vector int
# md[i,j] = ms1[i,j] * vs2[j]
memulcr.mv md, ms1, vs2
mwemulcr.mv md, ms1, vs2  # output double widen
mqemulcr.mv md, ms1, vs2  # output quadruple widen

# float matrix element-wise multiply with a row of vector float
# md[i,j] = ms1[i,j] * vs2[j]
mfemulcr.mv md, ms1, vs2
mfwemulcr.mv md, ms1, vs2  # output double widen
```

For m*emulcc.mv instructions, the vector operand will broadcast from a column to a c matrix.

```
# int matrix element-wise multiply with a column of vector int,
# md[i,j] = ms1[i,j] * vs2[i]
memulcc.mv md, ms1, vs2
mwemulcc.mv md, ms1, vs2  # output double widen
mqemulcc.mv md, ms1, vs2  # output quadruple widen

# float matrix element-wise multiply with a column of vector float,
# md[i,j] = ms1[i,j] * vs2[i]
mfemulcc.mv md, ms1, vs2
mfwemulcc.mv md, ms1, vs2  # output double widen
```

==== Matrix element-wise add

Matrix element-wise add instructions, the vector operand will broadcast to a matrix.

For m*addcr.mv instructions, the vector operand will broadcast from a row to a c matrix.

```
# int matrix element-wise add with a row of vector int
# md[i,j] = ms1[i,j] + vs2[j]
maddcr.mv md, ms1, vs2
mwaddcr.mv md, ms1, vs2  # output double widen
mqaddcr.mv md, ms1, vs2  # output quadruple widen

# float matrix element-wise add with a row of vector float
# md[i,j] = ms1[i,j] + vs2[j]
mfaddcr.mv md, ms1, vs2
mfwaddcr.mv md, ms1, vs2  # output double widen
```

For m*addcc.mv instructions, the vector operand will broadcast from a column to a c matrix.

```
# int matrix element-wise add with a column of vector int,
# md[i,j] = ms1[i,j] + vs2[i]
maddcc.mv md, ms1, vs2
mwaddcc.mv md, ms1, vs2  # output double widen
mqaddcc.mv md, ms1, vs2  # output quadruple widen

# float matrix element-wise add with a column of vector float,
# md[i,j] = ms1[i,j] + vs2[i]
mfaddcc.mv md, ms1, vs2
mfwaddcc.mv md, ms1, vs2  # output double widen
```

==== Matrix element-wise fused multiply-accumulate

Matrix element-wise fused multiply-add instructions, the vector operand will broadcast to a matrix.

For m*macccr.mv instructions, the vector operand will broadcast from a row to a c matrix.

```
# int matrix element-wise multiply-accumulate with a row of vector int
# md[i,j] = vs1[j] * md[i,j] + vs2[j]
mmacccr.mv md, vs1, vs2
mwmacccr.mv md, vs1, vs2  # output double widen
mqmacccr.mv md, vs1, vs2  # output quadruple widen

# float matrix element-wise multiply-accumulate with a row of vector float
# md[i,j] = vs1[j] * md[i,j] + vs2[j]
mfmacccr.mv md, vs1, vs2
mfwmacccr.mv md, vs1, vs2  # output double widen
```

For m*macccc.mv instructions, the vector operand will broadcast from a column to a c matrix.

```
# int matrix element-wise multiply-accumulate with a column of vector int,
# md[i,j] = vs1[i] * md[i,j] + vs2[i]
mmacccc.mv md, vs1, vs2
mwmacccc.mv md, vs1, vs2  # output double widen
mqmacccc.mv md, vs1, vs2  # output quadruple widen

# float matrix element-wise add with a column of vector float,
# md[i,j] = vs1[i] * md[i,j] + vs2[i]
mfmacccc.mv md, vs1, vs2
mfwmacccc.mv md, vs1, vs2  # output double widen
```

==== Instruction Listing

[cols="^2,5,^3,^2,^2,^2,^2,^2,^3"]
|===
| No.  |          | **31  26** | 25   | 24 20 | 19 15 | 14  12 | 11 7 | 6    0

2+|**Load**            ^| funct6 | ls   | rs2   | rs1   | eew    | md   | opcode
| 1    | mlae8.v        | 100001 | 0    | rs2   | rs1   | 000    | md   | 1110111
| 2    | mlae16.v       | 100001 | 0    | rs2   | rs1   | 001    | md   | 1110111
| 3    | mlae32.v       | 100001 | 0    | rs2   | rs1   | 010    | md   | 1110111
| 4    | mlae64.v       | 100001 | 0    | rs2   | rs1   | 011    | md   | 1110111
| 5    | mlbe8.v        | 100010 | 0    | rs2   | rs1   | 000    | md   | 1110111
| 6    | mlbe16.v       | 100010 | 0    | rs2   | rs1   | 001    | md   | 1110111
| 7    | mlbe32.v       | 100010 | 0    | rs2   | rs1   | 010    | md   | 1110111
| 8    | mlbe64.v       | 100010 | 0    | rs2   | rs1   | 011    | md   | 1110111
| 9    | mlce8.v        | 100000 | 0    | rs2   | rs1   | 000    | md   | 1110111
| 10   | mlce16.v       | 100000 | 0    | rs2   | rs1   | 001    | md   | 1110111
| 11   | mlce32.v       | 100000 | 0    | rs2   | rs1   | 010    | md   | 1110111
| 12   | mlce64.v       | 100000 | 0    | rs2   | rs1   | 011    | md   | 1110111

2+|**Store**           ^| funct6 | ls   | rs2   | rs1   | eew    | ms3  | opcode
| 13   | msae8.v        | 100001 | 1    | rs2   | rs1   | 000    | ms3  | 1110111
| 14   | msae16.v       | 100001 | 1    | rs2   | rs1   | 001    | ms3  | 1110111
| 15   | msae32.v       | 100001 | 1    | rs2   | rs1   | 010    | ms3  | 1110111
| 16   | msae64.v       | 100001 | 1    | rs2   | rs1   | 011    | ms3  | 1110111
| 17   | msbe8.v        | 100010 | 1    | rs2   | rs1   | 000    | ms3  | 1110111
| 18   | msbe16.v       | 100010 | 1    | rs2   | rs1   | 001    | ms3  | 1110111
| 19   | msbe32.v       | 100010 | 1    | rs2   | rs1   | 010    | ms3  | 1110111
| 20   | msbe64.v       | 100010 | 1    | rs2   | rs1   | 011    | ms3  | 1110111
| 21   | msce8.v        | 100000 | 1    | rs2   | rs1   | 000    | ms3  | 1110111
| 22   | msce16.v       | 100000 | 1    | rs2   | rs1   | 001    | ms3  | 1110111
| 23   | msce32.v       | 100000 | 1    | rs2   | rs1   | 010    | ms3  | 1110111
| 24   | msce64.v       | 100000 | 1    | rs2   | rs1   | 011    | ms3  | 1110111


2+|**Data Move**       ^| funct6 | v2m  | rs2   | *s1   | funct3 | *d   | opcode
| 25   | mmvar.v.m      | 000001 | 0    | rs2   | ms1   | 101    | vd   | 1110111
| 26   | mmvar.m.v      | 000001 | 1    | rs2   | vs1   | 101    | md   | 1110111
| 27   | mmvbr.v.m      | 000010 | 0    | rs2   | ms1   | 101    | vd   | 1110111
| 28   | mmvbr.m.v      | 000010 | 1    | rs2   | vs1   | 101    | md   | 1110111
| 29   | mmvcr.v.m      | 000000 | 0    | rs2   | ms1   | 101    | vd   | 1110111
| 30   | mmvcr.m.v      | 000000 | 1    | rs2   | vs1   | 101    | md   | 1110111

| 31   | mmvac.v.m      | 000101 | 0    | rs2   | ms1   | 101    | vd   | 1110111
| 32   | mmvac.m.v      | 000101 | 1    | rs2   | vs1   | 101    | md   | 1110111
| 33   | mmvbc.v.m      | 000110 | 0    | rs2   | ms1   | 101    | vd   | 1110111
| 34   | mmvbc.m.v      | 000110 | 1    | rs2   | vs1   | 101    | md   | 1110111
| 35   | mmvcc.v.m      | 000100 | 0    | rs2   | ms1   | 101    | vd   | 1110111
| 36   | mmvcc.m.v      | 000100 | 1    | rs2   | vs1   | 101    | md   | 1110111

| 37   | mwmvcr.v.m     | 010000 | 0    | rs2   | ms1   | 101    | vd   | 1110111
| 38   | mwmvcr.m.v     | 010000 | 1    | rs2   | vs1   | 101    | md   | 1110111

| 39   | mwmvcc.v.m     | 010100 | 0    | rs2   | ms1   | 101    | vd   | 1110111
| 40   | mwmvcc.m.v     | 010100 | 1    | rs2   | vs1   | 101    | md   | 1110111

| 41   | mqmvcr.v.m     | 100000 | 0    | rs2   | ms1   | 101    | vd   | 1110111
| 42   | mqmvcr.m.v     | 100000 | 1    | rs2   | vs1   | 101    | md   | 1110111

| 43   | mqmvcc.v.m     | 100100 | 0    | rs2   | ms1   | 101    | vd   | 1110111
| 44   | mqmvcc.m.v     | 100100 | 1    | rs2   | vs1   | 101    | md   | 1110111

2+|**Arithmetic**      ^| funct6 | fp   | vs2   | ms1   | funct3 | md   | opcode
| 45   | memulcr.mv     | 100001 | 0    | vs2   | ms1   | 110    | md   | 1110111
| 46   | mfemulcr.mv    | 100001 | 1    | vs2   | ms1   | 110    | md   | 1110111
| 47   | mwemulcr.mv    | 100010 | 0    | vs2   | ms1   | 110    | md   | 1110111
| 48   | mfwemulcr.mv   | 100010 | 1    | vs2   | ms1   | 110    | md   | 1110111
| 49   | mqemulcr.mv    | 100011 | 0    | vs2   | ms1   | 110    | md   | 1110111
| 50   | memulcc.mv     | 100100 | 0    | vs2   | ms1   | 110    | md   | 1110111
| 51   | mfemulcc.mv    | 100100 | 1    | vs2   | ms1   | 110    | md   | 1110111
| 52   | mwemulcc.mv    | 100101 | 0    | vs2   | ms1   | 110    | md   | 1110111
| 53   | mfwemulcc.mv   | 100101 | 1    | vs2   | ms1   | 110    | md   | 1110111
| 54   | mqemulcc.mv    | 100110 | 0    | vs2   | ms1   | 110    | md   | 1110111

| 55   | maddcr.mv      | 100111 | 0    | vs2   | ms1   | 110    | md   | 1110111
| 56   | mfaddcr.mv     | 100111 | 1    | vs2   | ms1   | 110    | md   | 1110111
| 57   | mwaddcr.mv     | 101000 | 0    | vs2   | ms1   | 110    | md   | 1110111
| 58   | mfwaddcr.mv    | 101000 | 1    | vs2   | ms1   | 110    | md   | 1110111
| 59   | mqaddcr.mv     | 101001 | 0    | vs2   | ms1   | 110    | md   | 1110111
| 60   | maddcc.mv      | 101010 | 0    | vs2   | ms1   | 110    | md   | 1110111
| 61   | mfaddcc.mv     | 101010 | 1    | vs2   | ms1   | 110    | md   | 1110111
| 62   | mwaddcc.mv     | 101011 | 0    | vs2   | ms1   | 110    | md   | 1110111
| 63   | mfwaddcc.mv    | 101011 | 1    | vs2   | ms1   | 110    | md   | 1110111
| 64   | mqaddcc.mv     | 101100 | 0    | vs2   | ms1   | 110    | md   | 1110111

| 55   | mmacccr.mv     | 101101 | 0    | vs2   | vs1   | 110    | md   | 1110111
| 56   | mfmacccr.mv    | 101101 | 1    | vs2   | vs1   | 110    | md   | 1110111
| 57   | mwmacccr.mv    | 101110 | 0    | vs2   | vs1   | 110    | md   | 1110111
| 58   | mfwmacccr.mv   | 101110 | 1    | vs2   | vs1   | 110    | md   | 1110111
| 59   | mqmacccr.mv    | 101111 | 0    | vs2   | vs1   | 110    | md   | 1110111
| 60   | mmacccc.mv     | 110000 | 0    | vs2   | vs1   | 110    | md   | 1110111
| 61   | mfmacccc.mv    | 110000 | 1    | vs2   | vs1   | 110    | md   | 1110111
| 62   | mwmacccc.mv    | 110001 | 0    | vs2   | vs1   | 110    | md   | 1110111
| 63   | mfwmacccc.mv   | 110001 | 1    | vs2   | vs1   | 110    | md   | 1110111
| 64   | mqmacccc.mv    | 110010 | 0    | vs2   | vs1   | 110    | md   | 1110111

|===


====  Intrinsic Examples: Matrix multiplication fused with element-wise vector operation

```
void fused_matmul_relu_float16(c, a, b, m, k, n) {
    msettype(e16);                              // use 16bit input matrix element
    for (i=0; i<m; i+=tile_m) {                 // loop at dim m with tiling
        tile_m = msettile_m(m-i);
        for (j=0; j<n; j+=tile_n) {             // loop at dim n with tiling
            tile_n = msettile_n(n-j);

            acc = mfemul_mf(acc, 0.f)           // clear acc reg
            for (s=0; s<k; s+=tile_k) {         // loop at dim k with tiling
                tile_k = msettile_k(k-s);

                tr1 = mlae16_m(&a[i][s]);       // load left matrix a
                tr2 = mlbe16_m(&b[s][j]);       // load right matrix b
                acc = mfwma_mm(tr1, tr2);       // tiled matrix multiply,
                                                // double widen output acc
            }

            acc = mfncvt_f_fw_m(acc);           // convert widen result to single


            for (s=0; s<tile_m; s+=rows) {
                rows = min(tile_m - s, 8*vlenb/rlenb); // max rows could move into 8 vregs
                vsetvl(tile_n*rows, e16, m8);

                v1 = mmvcr_v_m(acc, s);         // move acc rows to vreg
                v1 = vfmax_vf(0.f, v1);         // vfmax.vf for relu

                msce16_v(v1, &c[i+s][j], n);    // store output tile slices
            }
        }
    }
}

```

=== Zmbf16: Matrix Bfloat16(BF16) Extension

The Zmbf16 extension allows to use BF16 format as the data type of input matrix elements.

The Zmbf16 extension add a bit `mtype[4]` in `mtype` register.

.`mtype` register layout
[cols="^2,^2,8"]
|===
|     Bits | Name       | Description

|   XLEN-1 | mill       | Illegal value if set
| XLEN-2:5 | 0          | Reserved if non-zero
|        4 | **mbf16**  | **Use BF16 input format**
|        3 | maccq      | Support quad-width accumulator element
|      2:0 | msew[2:0]  | Selected element width (SEW) setting
|===


The new `mtype` value is encoded in the immediate fields of msettypei, and in the rs1 register for msettype.

```
Suggested bf16 assembler name used for msettypei mtypei immediate

    bf16  # Use BF16 format

Examples:

    msettypei t0, e16, bf16         # SEW = 16, use BF16 as input matrix element

```

For implemention not support Bfloat16 format, `mtype.mill` will be set.

`bf16` should be always used with `e16`(SEW=16), otherwise `mtype.mill` will be set.


=== Zmtf32: Matrix TensorFloat-32(TF32) Extension

The Zmtf32 extension allows to use TF32 FMA for matrix multiplication.

TF32 implementions are designed to achieve better performance on matrix multiplications and convolutions
by rounding input Float32 data to have 10 bits of mantissa, and accumulating results with FP32 precision,
maintaining FP32 dynamic range.

So when Zmtf32 is used, Float32 is still used as the input and output data type for matrix multiplication.

The Zmtf32 extension add a bit `mtype[5]` in `mtype` register.

.`mtype` register layout
[cols="^2,^2,8"]
|===
|     Bits | Name       | Description

|   XLEN-1 | mill       | Illegal value if set
| XLEN-2:6 | 0          | Reserved if non-zero
|        5 | **mtf32**  | **Enable TF32 FMA for matrix multiplication**
|        4 | mbf16      | Use bfloat16 input format
|        3 | maccq      | Support quad-width accumulator element
|      2:0 | msew[2:0]  | Selected element width (SEW) setting
|===


The new `mtype` value is encoded in the immediate fields of msettypei, and in the rs1 register for msettype.

```
Suggested tf32 assembler name used for msettypei mtypei immediate

    tf32  # enable TF32 FMA

Examples:

    msettypei t0, e32, tf32         # SEW = 32, enable TF32 FMA

```

For implemention not support TF32 format, `mtype.mill` will be set.

`tf32` should be always used with `e32`(SEW=32), otherwise `mtype.mill` will be set.


=== Zmic: Im2col Matrix Multiplication Extension

Im2col stands for Image to Column, and is an implementation technique of computing Convolution operation
(in Machine Learning) using GEMM operations.

The Zmic extension allows to perform the im2col operation on-the-fly, by the new load instructions.

The **Load Unfold** instructions allows to load and extract sliding local blocks from memory into the matrix tile registers.
And also, **Store Fold** instructions allows to store and combine an array of sliding local blocks from the matrix tile regstiers into memory.
Similar to PyTorch, for the case of two output spatial dimensions this operation is sometimes called `col2im`.

==== CSRs

The matrix extension adds 5 unprivileged CSRs (mkrsh, mfdsh, mpad, mstdi, msk) to the base scalar RISC-V ISA.

.New matrix CSRs
[cols="^2,^2,^2,10",options="header"]
|===
| Address | Privilege  | Name   | Description

| 0xC45 | URO | moutsh | Fold/unfold output shape
| 0xC46 | URO | minsh  | Fold/unfold input shape
| 0xC47 | URO | mpad   | Fold/unfold padding and sliding strides
| 0xC48 | URO | mstdi  | Fold/unfold sliding strides and dilations
| 0xC49 | URO | minsk  | Fold/unfold sliding kernel position of input
| 0xC50 | URO | moutsk | Fold/unfold sliding kernel position of output
|===


.`minsh` `moutsh` register layout
[cols="^2,^2,8"]
|===
|     Bits | Name       | Description

|  XLEN:32 | 0          | Reserved
|    31:16 | shape[1]   | shape of dim 1, height
|     15:0 | shape[0]   | shape of dim 0, width
|===

.`mpad` register layout
[cols="^2,^2,8"]
|===
|     Bits | Name        | Description

|  XLEN:32 | 0           | Reserved
|    31:24 | mpad_top    | Padding added to up side of input
|    23:16 | mpad_bottom | Padding added to bottom side of input
|     15:8 | mpad_left   | Padding added to left side of input
|      7:0 | mpad_right  | Padding added to left side of input
|===

.`mstdi` register layout
[cols="^2,^2,8"]
|===
|     Bits | Name        | Description

|  XLEN:32 | 0           | Reserved
|    31:24 | mdil_h      | Height spacing of the kernel elements
|    23:16 | mdil_w      | Weight spacing of the kernel elements
|     15:8 | mstr_h      | Height stride of the convolution
|      7:0 | mstr_w      | Weight stride of the convolution
|===

.`minsk` `moutsk` register layout
[cols="^2,^2,8"]
|===
|     Bits | Name        | Description

|  XLEN:32 | 0           | Reserved
|    31:16 | msk[1]      | Sliding kernel position of dim 1, height
|     15:0 | msk[0]      | Sliding kernel position of dim 0, width
|===

==== Configuration Instructions

```
msetoutsh rd, rs1, rs2  # set output shape(rs1), strides and dilations(rs2)
msetinsh rd, rs1, rs2   # set input shape(rs1) and padding(rs2)

msetsk rd, rs1, rs2     # set fold/unfold sliding positions, insk(rs1), outsk(rs2)
```


==== Load Unfold Instructions

The **Load Unfold** instructions allows to load and extract sliding local blocks from memory into the matrix tile registers.
Similar to PyTorch, for the case of two input spatial dimensions this operation is sometimes called `im2col`.

```
# md destination, rs1 base address, rs2 row byte stride

# for left matrix, a
mlufae8.m    md, (rs1), rs2
mlufae16.m   md, (rs1), rs2
mlufae32.m   md, (rs1), rs2
mlufae64.m   md, (rs1), rs2
```

==== Store Fold Instructions

The **Store Fold** instructions allows to store and combine an array of sliding local blocks from the matrix tile regstiers into memory.
Similar to PyTorch, for the case of two output spatial dimensions this operation is sometimes called `col2im`.

```
# ms3 destination, rs1 base address, rs2 row byte stride

# for left matrix, a
msfdae8.m    ms3, (rs1), rs2
msfdae16.m   ms3, (rs1), rs2
msfdae32.m   ms3, (rs1), rs2
msfdae64.m   ms3, (rs1), rs2
```

==== Instruction Listing

[cols="^2,5,^3,^2,^2,^2,^2,^2,^3"]
|===
| No.  |          | **31  28** | 27  25 | 24 20 | 19 15 | 14  12 | 11 7 | 6    0
2+|**Configuration**   ^|funct4   | 000 | rs2   | rs1   | funct3 | rd   | opcode
| 2    | msetoutsh      | 1000    | 000 | rs2   | rs1   | 111    | rd   | 1110111
| 4    | mseindsh       | 1001    | 000 | rs2   | rs1   | 111    | rd   | 1110111
| 6    | msetsk         | 1010  2+| 00000000    | rs1   | 111    | rd   | 1110111



| No.  |          | **31  26** | 25   | 24 20 | 19 15 | 14  12 | 11 7 | 6    0

2+|**Load**            ^| funct6 | ls   | rs2   | rs1   | eew    | md   | opcode
| 1    | mlufae8.m      | 110001 | 0    | rs2   | rs1   | 000    | md   | 1110111
| 2    | mlufae16.m     | 110001 | 0    | rs2   | rs1   | 001    | md   | 1110111
| 3    | mlufae32.m     | 110001 | 0    | rs2   | rs1   | 010    | md   | 1110111
| 4    | mlufae64.m     | 110001 | 0    | rs2   | rs1   | 011    | md   | 1110111
| 5    | mlufbe8.m      | 110010 | 0    | rs2   | rs1   | 000    | md   | 1110111
| 6    | mlufbe16.m     | 110010 | 0    | rs2   | rs1   | 001    | md   | 1110111
| 7    | mlufbe32.m     | 110010 | 0    | rs2   | rs1   | 010    | md   | 1110111
| 8    | mlufbe64.m     | 110010 | 0    | rs2   | rs1   | 011    | md   | 1110111
| 9    | mlufce8.m      | 110000 | 0    | rs2   | rs1   | 000    | md   | 1110111
| 10   | mlufce16.m     | 110000 | 0    | rs2   | rs1   | 001    | md   | 1110111
| 11   | mlufce32.m     | 110000 | 0    | rs2   | rs1   | 010    | md   | 1110111
| 12   | mlufce64.m     | 110000 | 0    | rs2   | rs1   | 011    | md   | 1110111

2+|**Store**           ^| funct6 | ls   | rs2   | rs1   | eew    | ms3  | opcode
| 13   | msfdae8.m      | 110001 | 1    | rs2   | rs1   | 000    | ms3  | 1110111
| 14   | msfdae16.m     | 110001 | 1    | rs2   | rs1   | 001    | ms3  | 1110111
| 15   | msfdae32.m     | 110001 | 1    | rs2   | rs1   | 010    | ms3  | 1110111
| 16   | msfdae64.m     | 110001 | 1    | rs2   | rs1   | 011    | ms3  | 1110111
| 17   | msfdbe8.m      | 110010 | 1    | rs2   | rs1   | 000    | ms3  | 1110111
| 18   | msfdbe16.m     | 110010 | 1    | rs2   | rs1   | 001    | ms3  | 1110111
| 19   | msfdbe32.m     | 110010 | 1    | rs2   | rs1   | 010    | ms3  | 1110111
| 20   | msfdbe64.m     | 110010 | 1    | rs2   | rs1   | 011    | ms3  | 1110111
| 21   | msfdce8.m      | 110000 | 1    | rs2   | rs1   | 000    | ms3  | 1110111
| 22   | msfdce16.m     | 110000 | 1    | rs2   | rs1   | 001    | ms3  | 1110111
| 23   | msfdce32.m     | 110000 | 1    | rs2   | rs1   | 010    | ms3  | 1110111
| 24   | msfdce64.m     | 110000 | 1    | rs2   | rs1   | 011    | ms3  | 1110111


|===


====  Intrinsic Examples: Conv2D

```
void conv2d_float16(c, a, b, outh, outw, outc, inh, inw, inc,
        kh, kw, pt, pb, pl, pr, sw, dilh, dilw) {
    m = outh * outw;
    k = kh * kw * inc;
    n = outc;

    msettype(e16);                              // use 16bit input matrix element

    // set in/out shape, sliding strides and dilations, and padding
    msetoutsh(outh << 16 | outw, dilh << 24 | dilw << 16 | sh << 8 | sw);
    msetinsh(inh << 16 | inw, pt << 24 | pb << 16 | pl << 8 | pr);

    for (i=0; i<m; i+=tile_m) {                 // loop at dim m with tiling
        tile_m = msettile_m(m-i);

        outh_pos = i / outw;
        outw_pos = i - outh_pos * outw;

        for (j=0; j<n; j+=tile_n) {             // loop at dim n with tiling
            tile_n = msettile_n(n-j);

            acc = mfemul_mf(acc, 0.f)           // clear acc reg
            for (skh=0; skh<kh; skh++) {        // loop for kernel height
                inh_pos = outh_pos * sh - pt + skh * dh;
                for (skw=0; skw<kw; skw++) {    // loop for kernel width
                    inw_pos = outw_pos * sw - pl + skw * dw;

                    msetsk(inh_pos << 16 | inw_pos, skw * dilw << 16 | outw_pos)
                                                // set sliding position

                    for (skc=0; skc<inc; skc+=tile_k) { // loop for kernel channels
                        tile_k = msettile_k(inc-skc);

                        tr1 = mlufae16_m(&a[inh_pos][inw_pos][skc]);
                                                    // load and unfold input blocks
                        tr2 = mlbe16_m(&b[s][j]);   // load right matrix b
                        acc = mfwma_mm(tr1, tr2);   // tiled matrix multiply,
                                                    // double widen output acc
                    }
                }
            }

            acc = mfncvt_f_fw_m(acc);           // convert widen result
            msce16_m(acc, &c[i][j], n*2);       // store to matrix c
        }
    }
}

```

====  Intrinsic Examples: Conv3D

```
void conv3d_float16(c, a, b, outh, outw, outc, ind, inh, inw, inc,
        kd, kh, kw, pt, pb, pl, pr, sw, dilh, dilw) {
    m = outh * outw;
    k = kd * kh * kw * inc;
    n = outc;

    msettype(e16);                              // use 16bit input matrix element

    // set in/out shape, sliding strides and dilations, and padding
    msetoutsh(outh << 16 | outw, dilh << 24 | dilw << 16 | sh << 8 | sw);
    msetinsh(inh << 16 | inw, pt << 24 | pb << 16 | pl << 8 | pr);

    for (i=0; i<m; i+=tile_m) {                 // loop at dim m with tiling
        tile_m = msettile_m(m-i);

        outh_pos = i / outw;
        outw_pos = i - outh_pos * outw;

        for (j=0; j<n; j+=tile_n) {             // loop at dim n with tiling
            tile_n = msettile_n(n-j);

            acc = mfemul_mf(acc, 0.f)           // clear acc reg
            for (skd=0; skd<kd; skd++) {        // loop for kernel *depth*
                for (skh=0; skh<kh; skh++) {        // loop for kernel height
                    inh_pos = outh_pos * sh - pt + skh * dh;
                    for (skw=0; skw<kw; skw++) {    // loop for kernel width
                        inw_pos = outw_pos * sw - pl + skw * dw;

                        msetsk(inh_pos << 16 | inw_pos, skw * dilw << 16 | outw_pos)
                                                // set sliding position

                        for (skc=0; skc<inc; skc+=tile_k) {
                            tile_k = msettile_k(inc-skc);

                            tr1 = mlufae16_m(&a[skd][inh_pos][inw_pos][skc]);
                                                      // load and unfold blocks
                            tr2 = mlbe16_m(&b[s][j]); // load right matrix b
                            acc = mfwma_mm(tr1, tr2); // tiled matrix multiply,
                                                      // double widen output acc
                        }
                    }
                }
            }

            acc = mfncvt_f_fw_m(acc);           // convert widen result
            msce16_m(acc, &c[i][j], n*2);       // store to matrix c
        }
    }
}

```

====  Intrinsic Examples: MaxPool2D

```
void maxpool2d_float16(out, in, outh, outw, outc, inh, inw, inc,
        kh, kw, pt, pb, pl, pr, sw, dilh, dilw) {
    m = outh * outw;
    n = outc;

    msettype(e16);                              // use 16bit input matrix element

    // set in/out shape, sliding strides and dilations, and padding
    msetoutsh(outh << 16 | outw, dilh << 24 | dilw << 16 | sh << 8 | sw);
    msetinsh(inh << 16 | inw, pt << 24 | pb << 16 | pl << 8 | pr);

    for (i=0; i<m; i+=tile_m) {                 // loop at dim m with tiling
        tile_m = msettile_m(m-i);

        outh_pos = i / outw;
        outw_pos = i - outh_pos * outw;

        for (j=0; j<n; j+=tile_n) {             // loop at dim n with tiling
            tile_n = msettile_n(n-j);

            acc = mfemul_mf(acc, -inf)          // clear acc reg
            for (skh=0; skh<kh; skh++) {        // loop for kernel height
                inh_pos = outh_pos * sh - pt + skh * dh;
                for (skw=0; skw<kw; skw++) {    // loop for kernel width
                    inw_pos = outw_pos * sw - pl + skw * dw;

                    msetsk(inh_pos << 16 | inw_pos, skw * dilw << 16 | outw_pos)
                                                // set sliding position

                    // load and unfold matrix blocks
                    acc1 = mlufce16_m(&in[inh_pos][inw_pos][j]);
                    acc = mfmaxc_mm(acc, acc1);
                }
            }

            msce16_m(acc, &out[i][j], n*2);       // store to matrix c
        }
    }
}

```

====  Intrinsic Examples: AvgPool2D

```
void avgpool2d_float16(out, in, outh, outw, outc, inh, inw, inc,
        kh, kw, pt, pb, pl, pr, sw, dilh, dilw) {
    m = outh * outw;
    n = outc;

    msettype(e16);                              // use 16bit input matrix element

    // set in/out shape, sliding strides and dilations, and padding
    msetoutsh(outh << 16 | outw, dilh << 24 | dilw << 16 | sh << 8 | sw);
    msetinsh(inh << 16 | inw, pt << 24 | pb << 16 | pl << 8 | pr);

    for (i=0; i<m; i+=tile_m) {                 // loop at dim m with tiling
        tile_m = msettile_m(m-i);

        outh_pos = i / outw;
        outw_pos = i - outh_pos * outw;

        for (j=0; j<n; j+=tile_n) {             // loop at dim n with tiling
            tile_n = msettile_n(n-j);

            acc = mfemul_mf(acc, -inf)          // clear acc reg
            for (skh=0; skh<kh; skh++) {        // loop for kernel height
                inh_pos = outh_pos * sh - pt + skh * dh;
                for (skw=0; skw<kw; skw++) {    // loop for kernel width
                    inw_pos = outw_pos * sw - pl + skw * dw;

                    msetsk(inh_pos << 16 | inw_pos, skw * dilw << 16 | outw_pos)
                                                // set sliding position

                    // load and unfold matrix blocks
                    acc1 = mlufce16_m(&in[inh_pos][inw_pos][j]);
                    acc = mfaddc_mm(acc, acc1);
                }
            }

            acc = mfdivc_mf(acc, kh*kw);
            msce16_m(acc, &out[i][j], n*2);     // store to matrix c
        }
    }
}

```